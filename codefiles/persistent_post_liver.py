# # **[MED] [3D] [SEG] Swin UNETR**
# 
# A novel segmentation model termed Swin UNEt TRansformers (Swin UNETR). Specially for the task of 3D semantic segmentation.
# HSM change ipynb to pythonfile

# [![GitHub watch](https://img.shields.io/github/watchers/LeonidAlekseev/Swin-UNETR.svg?style=social&label=Watch&maxAge=2592000)](https://github.com/LeonidAlekseev/Swin-UNETR/)


### further detail
# for mem 4090 using train dataset cahce 12, 0.5 will demand 20G
# np 1.21.6 torch1.13.0+cu117
#### Environment
#### make sure use swin_unetr conda env
# conda activate swin_unetr

####
#  CUDA_VISIBLE_DEVICES=3,4 python -m torch.distributed.launch --master_port=29501 --nproc_per_node=2 /data/Swin-Unetr/Swin-UNETR/notebook/Swin_UNETR_MSD_Liver_Lung_DDP.py
import os
import random
import shutil
import yaml
from datetime import datetime
from tqdm import tqdm
import matplotlib.pyplot as plt
import argparse
import glob
import json
import pprint
import torch
import torch.nn as nn
import torch.backends.cudnn as cudnn
import numpy as np
import einops
import warnings
import logging
import wandb
from monai.transforms import (Compose, AsDiscrete, LoadImaged, EnsureChannelFirstd, ScaleIntensityRanged, CropForegroundd, Orientationd,
                               Spacingd, EnsureTyped, RandFlipd,RandShiftIntensityd, RandCropByPosNegLabeld, MapLabelValued, AsDiscreted,
                               RandScaleIntensityd,RandRotate90d, ToTensord, Resized,FgBgToIndicesd, Invertd)
from monai.handlers.utils import from_engine
from monai.data import (
    PersistentDataset,
    ThreadDataLoader,
    DataLoader,
    Dataset,
    CacheDataset,
    DistributedSampler,
    list_data_collate,
    load_decathlon_datalist,
    decollate_batch,
    set_track_meta,
)
from torch.utils.data import ConcatDataset
from monai.inferers import sliding_window_inference
from monai.networks.nets import SwinUNETR
from monai.metrics import DiceMetric
from monai.losses import DiceCELoss, DiceFocalLoss
from monai.utils import set_determinism
from monai.config import print_config
import sys
sys.path.append("/data/hyungseok/Swin-UNETR")

from utils.lr_scheduler import LinearWarmupCosineAnnealingLR
from utils.my_utils import *
from losses.contrastive import *

import torch.nn.functional as F


def main():
    
    parser = argparse.ArgumentParser(description="Swin UNETR training")
    parser.add_argument('--config', type=str, default="/data/hyungseok/Swin-UNETR/api/liver.yaml", help="Path to the YAML config file")
    args = parser.parse_args()
    # YAML ì„¤ì • íŒŒì¼ ë¡œë“œ
    def load_config(config_path):
        with open(config_path, 'r') as file:
            return yaml.safe_load(file)
    # í•™ìŠµ ì„¤ì • ë¡œë“œ
    config_path = args.config
    config = load_config(config_path)

    # í•™ìŠµí™˜ê²½ ì„¤ì •
    set_determinism(seed=config['train_params']['seed']) # 5ê°œ ìœµí•©
    torch.manual_seed(config['train_params']['seed'])
    torch.cuda.manual_seed(config['train_params']['seed'])
    torch.cuda.manual_seed_all(config['train_params']['seed'])
    random.seed(config['train_params']['seed'])
    np.random.seed(config['train_params']['seed'])
    cudnn.benchmark = config['cuda']['benchmark']
    cudnn.deterministic = config['cuda']['deterministic']
     
    os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
    os.environ["CUDA_VISIBLE_DEVICES"] = ",".join(map(str, config['cuda']['CUDA_VISIBLE_DEVICES']))
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # í´ë” êµ¬ì¡° ì„¤ì •
    experiment_name = generate_experiment_name(config)
    date = datetime.now().strftime("%Y-%m-%d_%H-%M")
    output_dir = os.path.join(config['data']['save_dir'], experiment_name,date)
    log_dir = os.path.join(config['data']['log_dir'], experiment_name,date)


    os.makedirs(output_dir, exist_ok=True) 
    os.makedirs(log_dir, exist_ok=True)
    # ë¡œê·¸ ì„¤ì •: log_dirì— ë¡œê·¸ ì €ì¥
    setup_logging(log_dir)
    # config íŒŒì¼ì„ JSONìœ¼ë¡œ ì €ì¥
    log_experiment_config()
    save_config_as_json(config, log_dir)
    # í•™ìŠµ ì‹œì‘ ë©”ì‹œì§€
    logging.info("Training started with configuration:")
    logging.info(config)

    wandb.init(project=config['wandb']['project_name'],name=config['wandb']['experiment_name'],
    config=config,dir=log_dir, mode=config['wandb']['mode'])
    
    # ê¸°ë¡í•˜ê³  ì‹¶ì€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    # Train, Trainer, model, loss ì •ë„?
    # Modelê³¼ Trainerì˜ ì†ŒìŠ¤ íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    # file_listì— ì¶”ê°€
    file_list = []
    # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ íŒŒì¼ ì¶”ê°€ (__file__ ë³€ìˆ˜ ì‚¬ìš©)
    if '__file__' in globals():
        file_list.append(os.path.abspath(__file__))
    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    tmp_dir = config['data']['tmp_dir']
    os.makedirs(tmp_dir, exist_ok=True)

    # íŒŒì¼ ë³µì‚¬
    for file_name in file_list:
        shutil.copy(file_name, tmp_dir)
    # ì„ì‹œ ë””ë ‰í† ë¦¬ë¥¼ wandbì— ê¸°ë¡
    wandb.run.log_code(tmp_dir)
    # ì‚¬ìš© í›„ ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
    shutil.rmtree(tmp_dir)
    current_script_name = __file__
    save_current_code(log_dir,current_script_name)
    # print_config()
    
    # ### Transforms
    # 2024.09.25 í˜„ì¬ labelì€ ì¢…ì–‘ë§Œ í•´ì„œ í•œê°€ì§€ë§Œ ë‚¨ê¹€
    # 2024.09.26 í˜„ì¬ patch 96 ìœ ì§€ ëª»í•´ì„œ ì¼ë‹¨ 64ë¡œ ì§„í–‰
    num_samples = config['transforms']['num_samples']
    liver_train_transforms = Compose(
        [
            LoadImaged(keys=["image", "label"]),
            # ì´ë¯¸ì§€ì™€ mask ë¡œë“œ 
            EnsureChannelFirstd(keys=["image", "label"]),
            Orientationd(keys=["image", "label"], axcodes="RAS"),
            # Spacingdë¥¼ ì‚¬ìš©í•˜ì—¬ ë“±ë°©ì„± voxel spacing 1.0mmë¡œ ë³´ê°„
            Spacingd(
                keys=["image", "label"],
                pixdim=tuple(config['transforms']['spacing']),
                mode=("bilinear", "nearest"),
            ),
            ScaleIntensityRanged(
                keys=["image"],
                a_min=config['transforms']['liver']['a_min'],
                a_max=config['transforms']['liver']['a_max'],
                b_min=0.0,
                b_max=1.0,
                clip=True,
            ),
            CropForegroundd(keys=["image", "label"], source_key="image"),
            FgBgToIndicesd(
                keys="label",
                fg_postfix="_fg",
                bg_postfix="_bg",
                image_key="image",
            ),
            RandCropByPosNegLabeld(
                keys=["image", "label"],
                label_key="label",
                spatial_size=tuple(config['train_params']['spatial_size']),
                pos=config['transforms']['liver']['RandCropByPosNegLabeld_params']['pos'],
                neg=config['transforms']['liver']['RandCropByPosNegLabeld_params']['neg'],
                num_samples=config['transforms']['num_samples'],
                fg_indices_key="label_fg",
                bg_indices_key="label_bg",
            ),
            # RandCropByPosNegLabeld(
            #     keys=["image", "label"],
            #     label_key="label",
            #     spatial_size=tuple(config['train_params']['spatial_size']),
            #     pos=config['transforms']['liver']['RandCropByPosNegLabeld_params']['pos'],
            #     neg=config['transforms']['liver']['RandCropByPosNegLabeld_params']['neg'],
            #     num_samples=config['transforms']['num_samples'],
            #     image_key="image",
            #     image_threshold=0,
            # ),
            RandFlipd(
                keys=["image", "label"],
                spatial_axis=[0],
                prob=config['transforms']['liver']['rand_flip_prob'],
            ),
            RandFlipd(
                keys=["image", "label"],
                spatial_axis=[1],
                prob=config['transforms']['liver']['rand_flip_prob'],
            ),
            RandFlipd(
                keys=["image", "label"],
                spatial_axis=[2],
                prob=config['transforms']['liver']['rand_flip_prob'],
            ),
            RandRotate90d(
                keys=["image", "label"],
                prob=config['transforms']['liver']['rand_rotate_prob'],
                max_k=3,
            ),
            RandScaleIntensityd(
                keys=["image"],
                factors=config['transforms']['liver']['rand_scale_intensity_factor'], 
                prob=config['transforms']['liver']['rand_scale_intensity_prob']),
            RandShiftIntensityd(
                keys=["image"],
                offsets=config['transforms']['liver']['rand_shift_intensity_offset'],
                prob=config['transforms']['liver']['rand_shift_intensity_prob'],
            ),
            EnsureTyped(keys=["image", "label"]),  # âœ… MetaTensor ë³€í™˜ ì¶”ê°€
        ]
    )

    liver_val_transforms = Compose(
            [
                LoadImaged(keys=["image", "label"]),
                EnsureChannelFirstd(keys=["image", "label"]),
                Orientationd(keys=["image"], axcodes="RAS"),
                Spacingd(
                    keys=["image"],
                    pixdim=tuple(config['transforms']['spacing']),
                    mode=("bilinear"),
                ),
                ScaleIntensityRanged(
                    keys=["image"], a_min=config['transforms']['liver']['a_min'], a_max=config['transforms']['liver']['a_max'], b_min=0.0, b_max=1.0, clip=True
                ),
                CropForegroundd(keys=["image"], source_key="image"),
                EnsureTyped(keys=["image", "label"]),
            ]
        )

    liver_post_pred = Compose([
        Invertd(
            keys="pred",  # ì˜ˆì¸¡ê°’ì—ë§Œ Invertd ì ìš©
            transform=liver_val_transforms,  # ì›ë³¸ê³¼ ë™ì¼í•œ ì „ì²˜ë¦¬
            orig_keys="image",  # ì›ë³¸ ë°ì´í„° í‚¤
            # meta_keys="pred_meta_dict",  # ë©”íƒ€ë°ì´í„° í‚¤
            # meta_key_postfix="meta_dict",  # ë©”íƒ€ë°ì´í„° ì ‘ë¯¸ì‚¬
            nearest_interp=True,  # ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒ ë³´ê°„
            to_tensor=True,  # í…ì„œë¡œ ë³€í™˜
            device="cpu",
        ),
        AsDiscreted(keys="pred",argmax=True,to_onehot=config['model_params']['out_channels']),
        AsDiscreted(keys="label",to_onehot=config['model_params']['out_channels'])
    ])

   
    # **ğŸ“Œ ëª¨ë“  ëœë¤ ë³€í™˜ì— ì‹œë“œ ì ìš©**
    set_all_random_states(liver_train_transforms.transforms, seed=1234)
    set_all_random_states(liver_val_transforms.transforms, seed=1234)
    # ### Dataset
    # set_track_meta(False) - Do not activate  (ì „ì²˜ë¦¬ì—ì„œ spacingdë“± ë©”íƒ€ì •ë³´ í•„ìš”í•œê²ƒì„ ëª»í•˜ê²Œ ë§‰ìŒ)
    set_track_meta(True)
    # ì´ë¯¸ì§€ ë° ë ˆì´ë¸” ê²½ë¡œê°€ ì €ì¥ëœ txt íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê¸°
   
    def load_liverfile_from_txt(image_txt_path, image_dir):
        image_paths = []
        label_paths = []
        
        # ì´ë¯¸ì§€ ê²½ë¡œ ì½ê¸°
        with open(image_txt_path, 'r') as f:
            for line in f:
                image_paths.append(os.path.join(image_dir, line.strip()))
                mask_filename = os.path.join(image_dir, line.strip()).replace('imagesTr', 'processed_labels')
                label_paths.append(mask_filename)
        return image_paths, label_paths

     # Train ë°ì´í„° ë¡œë“œ
    
    # Train ë°ì´í„° ë¡œë“œ
    liver_train_images, liver_train_labels = load_liverfile_from_txt(config['data']['liver_train_image_txt'], config['data']['liver_image_dir'])
    # Validation ë°ì´í„° ë¡œë“œ
    liver_val_images, liver_val_labels = load_liverfile_from_txt(config['data']['liver_val_image_txt'],  config['data']['liver_image_dir'])
    
   # Dataset êµ¬ì„±
    liver_dataset_json = {
        "labels": {
            "0": "background",
            "1": "cancer",
        },
        "tensorImageSize": "3D",
        "training": [{"image": img, "label": lbl} for img, lbl in zip(liver_train_images, liver_train_labels)],
        "validation": [{"image": img, "label": lbl} for img, lbl in zip(liver_val_images, liver_val_labels)]
    }

    ###json íŒŒì¼ ê²½ë¡œ

    liver_datasets = os.path.join(output_dir, 'liver_dataset.json')

    with open(liver_datasets, 'w') as outfile:
        json.dump(liver_dataset_json, outfile)
    pprint.pprint(liver_dataset_json)
    
    #### For Debug run below
    # lung_datasets = "/data/Swin-Unetr/Swin-UNETR/results/debug/lung_dataset_tsne.json"
    # liver_datasets = "/data/Swin-Unetr/Swin-UNETR/results/debug/liver_dataset_tsne.json"

    # CacheDataset ë° DataLoader êµ¬ì„±
    liver_train_files = load_decathlon_datalist(liver_datasets, True, "training")
    liver_val_files = load_decathlon_datalist(liver_datasets, True, "validation")

    
    liver_train_ds = PersistentDataset(data=liver_train_files, transform=liver_train_transforms, cache_dir="/data/hyungseok/Swin-UNETR/data_cache/Liver_Lung/Liver/train")
    

    liver_val_ds = PersistentDataset(data=liver_val_files, transform=liver_val_transforms,cache_dir="/data/hyungseok/Swin-UNETR/data_cache/Liver_Lung/Liver/val")
                                                                                
    
    liver_train_loader = DataLoader(liver_train_ds, batch_size=config['train_params']['batch_size'], 
        num_workers=config['train_params']['num_workers'], pin_memory=config['train_params']['pin_memory'],
        shuffle= True, worker_init_fn=worker_init_fn)
    liver_val_loader = DataLoader(liver_val_ds, batch_size=config['train_params']['val_batch_size'], 
        num_workers=config['train_params']['val_num_workers'], pin_memory=config['train_params']['pin_memory']
        ,worker_init_fn=worker_init_fn)
    

    #### Model
    ##### Create

    
    if config['model_params']['type'] == "SwinUnetr":
        model = SwinUNETR(
            img_size=config['model_params']['img_size'],
            in_channels=config['model_params']['in_channels'],
            out_channels=config['model_params']['out_channels'],
            feature_size=config['model_params']['feature_size'],
            use_checkpoint=config['model_params']['use_checkpoint']
        )
     
        
    # ### Load weights

    weight = torch.load(config['data']['weights_path'])
    model.load_from(weights=weight)
    if torch.cuda.device_count() > 1:
        model = nn.DataParallel(model)
    model = model.to(device)

    # ### Training


    def validation(epoch_iterator_val_liver):
        model.eval()
        dice_metric.reset()  # Reset metric at the start of validation
        with torch.no_grad():
            for step, batch in enumerate(epoch_iterator_val_liver):
                val_inputs = batch["image"].cuda()
                with torch.cuda.amp.autocast():
                    # val_outputs = sliding_window_inference(val_inputs, config['model_params']['img_size'], num_samples, lambda x: model(x, label=None,organ=organ_type))
                    batch["pred"] = sliding_window_inference(val_inputs, config['model_params']['img_size'], num_samples, model).detach().cpu()
                    batch = [liver_post_pred(i) for i in decollate_batch(batch)]
                    val_output_convert, val_labels_convert = from_engine(["pred", "label"])(batch)
                    val_output_convert = val_output_convert[0].unsqueeze(0)
                    val_labels_convert =val_labels_convert[0].unsqueeze(0)
                dice_metric(y_pred=val_output_convert, y=val_labels_convert)
                epoch_iterator_val_liver.set_description(
                    f"Validate Liver ({step + 1} / {len(epoch_iterator_val_liver)} Steps)"
                )
            mean_dice_val = dice_metric.aggregate().item()
            dice_metric.reset()
        return mean_dice_val



    def train(epoch, epoch_iterator):
        model.train()
        epoch_loss = 0
        epoch_contrastive_loss = 0
        dice_metric_train.reset()  # Reset Dice metric at the beginning of each epoch
        
        step=0
        for step, batch in enumerate(epoch_iterator):
            with torch.cuda.amp.autocast():
                x, y = (batch["image"].to(device), batch["label"].to(device))
                logit_map = model(x)
                loss = loss_function(logit_map, y)
            # Gradient Accumulationì„ ìœ„í•´ Lossë¥¼ ë‚˜ëˆ„ì–´ ì¶•ì 
            loss = loss / accumulation_steps
            scaler.scale(loss).backward()
            # ë§¤ `accumulation_steps` ë§ˆë‹¤ optimizer.step()ì„ í˜¸ì¶œ
            if (step + 1) % accumulation_steps == 0:
                scaler.unscale_(optimizer)
                scaler.step(optimizer)
                scaler.update()
                optimizer.zero_grad()
                
             # ì›ë˜ ì†ì‹¤ì„ ë³µì›í•˜ì—¬ ëˆ„ì 
            epoch_loss += loss.item() * accumulation_steps
            
            # Training Dice score ê³„ì‚° (10 ìŠ¤í…ë§ˆë‹¤ ìˆ˜í–‰)
            if step % 10 == 0:  # ë§¤ 10 ìŠ¤í…ë§ˆë‹¤ ìˆ˜í–‰
                y_pred = decollate_batch(logit_map)
                y_pred = [post_pred(i) for i in y_pred]
                y = decollate_batch(y)
                y = [post_label(i) for i in y]
                dice_metric_train(y_pred, y)
        
            epoch_iterator.set_description(
            "Training (%d / %d Steps) (loss=%2.5f)"
            % (epoch, max_epoch, loss * accumulation_steps))  # ì›ë˜ Lossë¡œ í‘œì‹œ
        
        # ë§ˆì§€ë§‰ ë‚¨ì€ ë¯¸ë‹ˆ ë°°ì¹˜ ì²˜ë¦¬
        if (step + 1) % accumulation_steps != 0 and accumulation_steps != 1:
            scaler.unscale_(optimizer)
            scaler.step(optimizer)
            scaler.update()
            optimizer.zero_grad()
            
        epoch_loss /= (step+1)
        epoch_contrastive_loss /= (step + 1)  # contrastive lossì˜ ì—í¬í¬ í‰ê·  ê³„ì‚°
        # Aggregate dice score
        train_dice = dice_metric_train.aggregate().item()
        dice_metric_train.reset()
        return epoch_loss ,epoch_contrastive_loss , train_dice

    max_epoch = config['train_params']['max_epoch']
    eval_epoch = config['train_params']['eval_epoch']
    if config['train_params']['loss_type'] == "DiceCELoss":
        loss_function = DiceCELoss(to_onehot_y=True, softmax=True)
    elif config['train_params']['loss_type'] == "DiceCELoss+Cont3":
        loss_function = DiceCELoss(to_onehot_y=True, softmax=True) 
        pixel_contrast_loss_function  = BalSCL([0.95,0.05],config['CONTRASTIVE']['TEMPERATURE']).cuda()
    elif config['train_params']['loss_type'] == "DiceCELoss+Cont1":
        loss_function = DiceFocalLoss(to_onehot_y=True,softmax=True,gamma=2.0,lambda_dice=1.0,lambda_focal=1.0)
        pixel_contrast_loss_function  = BalSCL([0.95,0.05],config['CONTRASTIVE']['TEMPERATURE']).cuda()
    if config['train_params']['optim_type'] == "AdamW":
        optimizer = torch.optim.AdamW(model.parameters(), lr=float(config['train_params']['learning_rate']), weight_decay=float(config['train_params']['weight_decay']))
    elif config['train_params']['optim_type'] == "SGD":
        optimizer = torch.optim.SGD(model.parameters(), lr=float(config['train_params']['learning_rate']), momentum=0.9)
        
    scheduler = LinearWarmupCosineAnnealingLR(optimizer, warmup_epochs=config['train_params']['warmup'], max_epochs=config['train_params']['max_epoch'])
    scaler = torch.cuda.amp.GradScaler() 
    post_label = AsDiscrete(to_onehot=config['model_params']['out_channels']) # class n
    post_pred = AsDiscrete(argmax=True, to_onehot=config['model_params']['out_channels']) # class n
    dice_metric = DiceMetric(include_background=True, reduction="mean", get_not_nans=False)
    temp_dice_metric = DiceMetric(include_background=True, reduction="mean", get_not_nans=False)
    dice_metric_train = DiceMetric(include_background=True, reduction="mean", get_not_nans=False)
    accumulation_steps = config['train_params']['gradient_accumulation_steps']
    
    epoch = 0
    dice_val_best = 0.0
    epoch_best = 0
    epoch_loss_values = []
    epoch_contrastive_loss_values=[]
    metric_values = []

    if config['train_params']['resume'] :
        logging.info("Loading checkpoint...")
        checkpoint = torch.load(config['train_params']['resume_path'])
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])  # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ë³µêµ¬
        scaler.load_state_dict(checkpoint['scaler_state_dict'])
        epoch = checkpoint['epoch']
        dice_val_best = checkpoint['best_dice']
        logging.info(f"Resuming from epoch {epoch} with best dice {dice_val_best:.4f}")
    
    while epoch < max_epoch:
        epoch_iterator_train = tqdm(
                liver_train_loader, desc="Training (X / X Steps) (dice=X.X)", dynamic_ncols=True
            )
        epoch_loss,epoch_contrastive_loss, train_dice = train(epoch, epoch_iterator_train)
        logging.info(f"Epoch {epoch}, Training loss {epoch_loss:.4f}, Cont loss {epoch_contrastive_loss : .4f}, Training Dice {train_dice:.4f}")
        wandb.log({"lr": scheduler.get_last_lr()[0], "training_loss": epoch_loss, "Cont_loss":epoch_contrastive_loss, "training_dice": train_dice},step=epoch)
        scheduler.step()
        # WandBë¡œ í•™ìŠµ ì†ì‹¤ ê¸°ë¡
        epoch_loss_values.append(epoch_loss)
        epoch_contrastive_loss_values.append(epoch_contrastive_loss)
        if (epoch % eval_epoch == 0 and epoch != 0) or epoch == max_epoch:
            liver_epoch_iterator_val = tqdm(
                liver_val_loader, desc="Validate (X / X Steps) (dice=X.X)", dynamic_ncols=True
            )
            dice_val = validation(liver_epoch_iterator_val)
            metric_values.append(dice_val)
            # WandBë¡œ ê²€ì¦ ê²°ê³¼ ê¸°ë¡
            wandb.log({"validation_dice": dice_val},step=epoch)
            if dice_val > dice_val_best:
                dice_val_best = dice_val
                epoch_best = epoch
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scaler_state_dict': scaler.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),  # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¶”ê°€
                    'epoch': epoch,
                    'best_dice': dice_val_best
                }, os.path.join(output_dir, "best_metric_model.pth"))
                logging.info(f"\nModel Was Saved ! Current {epoch} epoch is Best Avg. Dice: {dice_val_best}")
            else:
                logging.info(f"\nModel Was Not Saved ! Current Best Avg Dice at {epoch_best}epoch: {dice_val_best} Current {epoch}epoch Avg. Dice: {dice_val}")
        if (epoch % config['train_params']['save_epoch'] == 0 and epoch != 0):
            torch.save({
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scaler_state_dict': scaler.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),  # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¶”ê°€
                    'epoch': epoch,
                    'best_dice': dice_val_best
                },  os.path.join(output_dir,f"checkpoint_epoch_{epoch}.pth"))
            logging.info(f"\nCheckpoint frequently saved at epoch {epoch}.")
        epoch += 1
        # flush í˜¸ì¶œí•˜ì—¬ ë¡œê·¸ ì¦‰ì‹œ ê¸°ë¡
        for handler in logging.getLogger().handlers:
            handler.flush()

    logging.info(f"train completed, best_metric: {dice_val_best:.4f} at epoch: {epoch_best}")
    np.savez(os.path.join(output_dir, "training_metrics.npz"), epoch_loss_values=epoch_loss_values, metric_values=metric_values)

# ìµœì¢… í•™ìŠµ ê²°ê³¼ë¥¼ WandBì— ê¸°ë¡
    wandb.log({"best_metric": dice_val_best, "final_epoch": epoch_best})
    # checkpoint = torch.load(os.path.join(output_dir, "best_metric_model.pth"))
    # model.load_state_dict(checkpoint['model_state_dict'])
    
    ### show the progress of training
    plt.figure("train", (12, 6))
    plt.subplot(1, 2, 1)
    plt.title("epoch Average Loss")
    x = [eval_epoch * (i + 1) for i in range(len(epoch_loss_values))]
    y = epoch_loss_values
    plt.xlabel("epoch")
    plt.plot(x, y)
    plt.subplot(1, 2, 2)
    plt.title("Val Mean Dice")
    x = [eval_epoch * (i + 1) for i in range(len(metric_values))]
    y = metric_values
    plt.xlabel("epoch")
    plt.plot(x, y)
    # plt.show()
    # ê²½ë¡œì™€ íŒŒì¼ëª… ì§€ì •í•˜ì—¬ ì €ì¥
    plt.savefig(os.path.join(log_dir, f"training_progress_{epoch}.png"))
    plt.close()  # ì €ì¥ í›„ ì°½ ë‹«ê¸°



if __name__ == "__main__":
    main()
